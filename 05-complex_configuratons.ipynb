{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More complex configurations\n",
    "## Ways to handle multiple clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start from imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "from jobqueue_features.decorators import on_cluster, task\n",
    "from jobqueue_features.functions import set_default_cluster\n",
    "from jobqueue_features.clusters import CustomSLURMCluster\n",
    "from jobqueue_features.clusters_controller import (\n",
    "    clusters_controller_singleton as controller,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then define default cluster as `CustomSLURMCluster`, because those example working on SLURM docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_cluster(\n",
    "    CustomSLURMCluster\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's default tasks to provide on our cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@on_cluster()\n",
    "@task()\n",
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "\n",
    "@on_cluster(\n",
    "    cluster=CustomSLURMCluster(\n",
    "        name=\"other\", \n",
    "        walltime=\"00:01:00\"\n",
    "    )\n",
    ")\n",
    "@task(cluster_id=\"other\")\n",
    "def inc(x):\n",
    "    return x + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two clusters, a default one and one with the name `other`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    from distributed import as_completed\n",
    "    \n",
    "    sq_tasks = list(map(square, range(1, 11)))\n",
    "    inc_tasks = list(map(inc, range(1, 11)))\n",
    "    print(\n",
    "        \"Squares: \",\n",
    "        [t.result() for t in as_completed(sq_tasks)]\n",
    "    )\n",
    "    print(\n",
    "        \"Increments: \",\n",
    "        [t.result() for t in as_completed(inc_tasks)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "main()\n",
    "print(\"Executed in {}\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean up after ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller._close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration options\n",
    "\n",
    "We've hidden away the configuration of cluster, so you've never really had to think about it. Unfortunately the configuration can be quite complicated depending on how your local system is configured.\n",
    "\n",
    "First, let's look at the options that our `CustomSLURMCluster` can take (use `shift+tab` between the brackets below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CustomSLURMCluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having to set all those options all the time is very tedious so instead we can use a Dask configuration file (see the [Dask documentation](https://docs.dask.org/en/latest/configuration.html) for details on where this can be placed). \n",
    "\n",
    "Luckily the system is the same for all users, so such a file can be created universally. Let's take a look at the configuration file for a complex system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load /jobqueue_features/jobqueue_features/jobqueue_features.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this (admittedly complex) configuration file, it is relatively easy to configure different clusters to run on different parts of the resource (CPU, GPU, KNL) and have them communicate with each other."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
