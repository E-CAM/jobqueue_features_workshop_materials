{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More complex configurations\n",
    "## Ways to handle multiple clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start from imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "from jobqueue_features.decorators import on_cluster, task\n",
    "from jobqueue_features.functions import set_default_cluster\n",
    "from jobqueue_features.clusters import CustomSLURMCluster\n",
    "from jobqueue_features.clusters_controller import (\n",
    "    clusters_controller_singleton as controller,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then define default cluster as `CustomSLURMCluster`, because those example working on SLURM docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_cluster(\n",
    "    CustomSLURMCluster\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's default tasks to provide on our cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@on_cluster()\n",
    "@task()\n",
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "\n",
    "@on_cluster(\n",
    "    cluster=CustomSLURMCluster(\n",
    "        name=\"other\", \n",
    "        walltime=\"00:01:00\"\n",
    "    )\n",
    ")\n",
    "@task(cluster_id=\"other\")\n",
    "def inc(x):\n",
    "    return x + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two clusters, a default one and one with the name `other`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    from distributed import as_completed\n",
    "    \n",
    "    sq_tasks = list(map(square, range(1, 11)))\n",
    "    inc_tasks = list(map(inc, range(1, 11)))\n",
    "    print(\n",
    "        \"Squares: \",\n",
    "        [t.result() for t in as_completed(sq_tasks)]\n",
    "    )\n",
    "    print(\n",
    "        \"Increments: \",\n",
    "        [t.result() for t in as_completed(inc_tasks)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "main()\n",
    "print(\"Executed in {}\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean up after ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller._close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration options\n",
    "\n",
    "We've hidden away the configuration of cluster, so you've never really had to think about it. Unfortunately the configuration can be quite complicated depending on how your local system is configured.\n",
    "\n",
    "First, let's look at the options that our `CustomSLURMCluster` can take (use `shift+tab` between the brackets below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CustomSLURMCluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having to set all those options all the time is very tedious so instead we can use a Dask configuration file (see the [Dask documentation](https://docs.dask.org/en/latest/configuration.html) for details on where this can be placed). \n",
    "\n",
    "Luckily the system is the same for all users, so such a file can be created universally. Let's take a look at the configuration file for a complex system:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "jobqueue:\n",
    "  # JURECA general configuration\n",
    "  slurm:\n",
    "    name: dask-worker\n",
    "\n",
    "    # Dask worker options\n",
    "    cores: 24                 # Total number of cores per job, 24 physical on JURECA, 48 hyper-threaded, minimum\n",
    "                              # allocation one node\n",
    "    memory: 125GB             # Total amount of memory per job, it's 128GiB but leave some for OS\n",
    "    processes: 1              # Number of Python processes per job\n",
    "\n",
    "    interface: ib0            # Network interface to use like eth0 or ib0\n",
    "    death-timeout: 15         # Number of seconds to wait if a worker can not find a scheduler\n",
    "    local-directory: /tmp     # Location of fast local storage like /scratch or $TMPDIR\n",
    "\n",
    "    # SLURM resource manager options\n",
    "    shebang: \"#!/usr/bin/env bash\"\n",
    "    queue: batch\n",
    "    # project: null\n",
    "    walltime: '00:30:00'\n",
    "    worker-extra-args: []\n",
    "    job-script-prologue: []\n",
    "    job-cpu: null\n",
    "    job-mem: null\n",
    "    job-extra-directives: []\n",
    "    log-directory: null\n",
    "\n",
    "jobqueue-features:\n",
    "  scheduler: slurm\n",
    "\n",
    "  slurm:\n",
    "    default-queue-type: batch       # default queue_type to use\n",
    "    cores-per-node: 24              # Physical cores per node\n",
    "    hyperthreading-factor: 2        # hyperthreading factor available (only used to trigger a warning if we go beyond\n",
    "                                    # physical or an error if we go beyond logical cores)\n",
    "    minimum-cores: 24               # Minimum number of cores per dask worker is 1 full node (ignored in MPI mode)\n",
    "    gpu-job-extra-directives: []               # Only relevant for particular queue_type\n",
    "    warning: null\n",
    "    \n",
    "    # MPI/OpenMP related settings ----\n",
    "    mpi-mode: False                 # MPI mode is off by default\n",
    "    mpi-launcher: {\"implementation\": \"slurm\", \"launcher\": \"srun\"}  # Default launcher for MPI code (unused unless in MPI mode)\n",
    "    nodes: null                     # Default node allocation (unused unless in MPI mode, setting a value forces user to\n",
    "                                    # use ntasks_per_node and cpus_per_task)\n",
    "    ntasks-per-node: 24             # Default tasks per node (unused unless in MPI mode)\n",
    "    # cpus-per-task: 1                # Default cpus per task (unused unless in MPI mode, if default is 1 better not to\n",
    "    #                                 # set it since we can safely assume that already)\n",
    "    openmp-env-extra: ['export OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK}', 'export OMP_PROC_BIND=spread',\n",
    "                       'export OMP_PLACES=threads']\n",
    "\n",
    "    queue-type:\n",
    "      batch:\n",
    "        name: dask-worker-batch\n",
    "\n",
    "      gpus:\n",
    "        name: dask-worker-gpus\n",
    "        queue: gpus\n",
    "        gpu-job-extra-directives: ['--gres=gpu:4']\n",
    "        warning: \"Each worker has access to 4 GPUs, don't waste them\"\n",
    "\n",
    "      knl:\n",
    "        name: dask-worker-knl\n",
    "        queue: booster\n",
    "        cores: 64                   # Actual is 68 but reserve some for OS\n",
    "        minimum-cores: 64\n",
    "        cores-per-node: 64\n",
    "        memory: 93GB\n",
    "        ntasks-per-node: 64\n",
    "        hyperthreading-factor: 4    # hyperthreading factor available for KNL\n",
    "        warning: \"KNL workers must be started from within a running job (i.e., not from front end nodes)\"\n",
    "\n",
    "      mem256:\n",
    "        name: dask-worker-mem256\n",
    "        queue: mem256\n",
    "        memory: 253GB\n",
    "        warning: \"There are only 128 nodes of mem256 type, only use this category if you really need to\"\n",
    "\n",
    "      mem512:\n",
    "        name: dask-worker-mem512\n",
    "        queue: mem512\n",
    "        memory: 509GB\n",
    "        warning: \"There are only 64 nodes of mem512 type, if you don't need so much memory use mem256 instead\"\n",
    "\n",
    "      vis:\n",
    "        name: dask-worker-vis\n",
    "        queue: vis\n",
    "        memory: 509GB\n",
    "        gpu-job-extra-directives: ['--gres=gpu:2']\n",
    "        warning: \"Each vis worker has access to 2 GPUs, if you don't need them use mem512 instead\"\n",
    "\n",
    "      mem1024:\n",
    "        name: dask-worker-mem1024\n",
    "        queue: mem1024\n",
    "        memory: 1021GB\n",
    "        gpu-job-extra-directives: ['--gres=gpu:2']\n",
    "        warning: \"There are only 2 nodes of mem1024 type, only use this category if you really need to\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this (admittedly complex) configuration file, it is relatively easy to configure different clusters to run on different parts of the resource (CPU, GPU, KNL) and have them communicate with each other."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
