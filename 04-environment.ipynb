{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "extra-shame",
   "metadata": {},
   "source": [
    "# A \"real life\" example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from jobqueue_features import (\n",
    "    MPIEXEC,\n",
    "    CustomSLURMCluster,\n",
    ")\n",
    "from jobqueue_features import on_cluster, mpi_task, get_task_mpi_comm\n",
    "from jobqueue_features.clusters_controller import (\n",
    "    clusters_controller_singleton as controller,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-saint",
   "metadata": {},
   "source": [
    "In this case, let's allow each worker to use one node. Since we have 2\n",
    "available nodes, we can have a maximum of 2 running jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_cluster = CustomSLURMCluster(\n",
    "    name=\"mpiMultiCluster\",\n",
    "    nodes=1,\n",
    "    maximum_jobs=2,\n",
    "    mpi_mode=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-repeat",
   "metadata": {},
   "source": [
    "Instead of using `cluster` to identify the cluster to the decorator we can also\n",
    "use a string argument `cluster_id` to identify the cluster we need. This can be a useful\n",
    "alternative to passing around the cluster instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-bailey",
   "metadata": {},
   "outputs": [],
   "source": [
    "@mpi_task(cluster_id=custom_cluster.name)\n",
    "def lammps_task(input_file, run_steps=100):\n",
    "    from mpi4py import MPI\n",
    "    from lammps import PyLammps\n",
    "    \n",
    "    L = PyLammps()      # Initialise LAMMPS\n",
    "    L.file(input_file)  # Read the input file\n",
    "    L.run(run_steps)    # Simulate the system\n",
    "\n",
    "    if MPI.COMM_WORLD.Get_rank()==0:\n",
    "        return \"Potential energy: %s\" % L.eval(\"pe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-height",
   "metadata": {},
   "source": [
    "Now let's execute this task with an available default input file\n",
    "and a default of 100 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-idaho",
   "metadata": {},
   "outputs": [],
   "source": [
    "@on_cluster(cluster=custom_cluster)\n",
    "def my_lammps_job(input_file=\"in.melt\", run_steps=100):\n",
    "    return lammps_task(input_file, run_steps=run_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-seeking",
   "metadata": {},
   "outputs": [],
   "source": [
    "future = my_lammps_job(run_steps=2000)\n",
    "print(future.result())\n",
    "future.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-parameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "controller._close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-sacramento",
   "metadata": {},
   "source": [
    "## Computing environments\n",
    "But there should have been a problem with these tasks. It turns out that the `lammps` module is not available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lammps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-decline",
   "metadata": {},
   "source": [
    "Why didn't this trigger an error? This is because the computing environment on the nodes can be completely different to the one where our notebook is running. On the nodes `c1` and `c2` the LAMMPS python module is indeed available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-twins",
   "metadata": {},
   "source": [
    "On HPC systems it is frequently the case that you need to configure a very\n",
    "specific computing environment for your tasks. The package LAMMPS may come as an\n",
    "*environment module* that you need to load."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-phrase",
   "metadata": {},
   "source": [
    "We can handle the creation of our computing environment when we declare our\n",
    "cluster, for example,\n",
    "```\n",
    "GROMACS_gpu_cluster = CustomSLURMCluster(\n",
    "    name=\"GROMACS_gpu_cluster\",\n",
    "    nodes=2,\n",
    "    mpi_mode=True,\n",
    "    fork_mpi=True,\n",
    "    queue_type=\"gpus\",\n",
    "    maximum_jobs=5,\n",
    "    job_extra_directives=[\n",
    "        \"module load Intel\",\n",
    "        \"module load IntelMPI\",\n",
    "        \"module load GROMACS\",\n",
    "        \"module load dask\",\n",
    "        \"module load jobqueue_features\",\n",
    "    ],\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-ticket",
   "metadata": {},
   "source": [
    "In this way we can declare different clusters for different task workloads and have them interact"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
