{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complex computing environments\n",
    "Now let's imagine some non-trivial tasks that require specific environments in which to compute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from jobqueue_features.clusters import CustomSLURMCluster\n",
    "from jobqueue_features.decorators import on_cluster, mpi_task\n",
    "from jobqueue_features.mpi_wrapper import mpi_wrap, which\n",
    "from jobqueue_features.functions import set_default_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have 2 different architecture types in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HSW = True\n",
    "GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_cluster(CustomSLURMCluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our software environment on the nodes, we need to leverage `env_extra`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GPU:\n",
    "    GROMACS_gpu_cluster = CustomSLURMCluster(\n",
    "        name=\"GROMACS_gpu_cluster\",\n",
    "        walltime=\"00:05:00\",\n",
    "        queue = \"develgpus\",\n",
    "        nodes=2,\n",
    "        mpi_mode=True,\n",
    "        fork_mpi=True,\n",
    "        queue_type=\"gpus\",\n",
    "        maximum_scale=5,\n",
    "        env_extra=[\n",
    "            \"module --force purge\",\n",
    "            \"module use /usr/local/software/jureca/OtherStages\",\n",
    "            \"module load Stages/Devel-2019a\",\n",
    "            \"module load Intel\",\n",
    "            \"module load ParaStationMPI\",\n",
    "            \"module load GROMACS\",\n",
    "            \"module load GPUtil\",  # Only required for our hello_world2.py example\n",
    "            \"module load dask\",\n",
    "            \"module load jobqueue_features\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "if HSW:\n",
    "    GROMACS_cluster = CustomSLURMCluster(\n",
    "        name=\"GROMACS_cluster\",\n",
    "        walltime=\"00:05:00\",\n",
    "        queue = \"devel\",\n",
    "        nodes=2,\n",
    "        mpi_mode=True,\n",
    "        fork_mpi=True,\n",
    "        maximum_scale=5,\n",
    "        env_extra=[\n",
    "            \"module --force purge\",\n",
    "            \"module use /usr/local/software/jureca/OtherStages\",\n",
    "            \"module load Stages/Devel-2019a\",\n",
    "            \"module load Intel\",\n",
    "            \"module load ParaStationMPI\",\n",
    "            \"module load GROMACS\",\n",
    "            \"module load dask\",\n",
    "            \"module load jobqueue_features\",\n",
    "        ],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GPU:\n",
    "\n",
    "    @on_cluster(cluster=GROMACS_gpu_cluster, cluster_id=\"GROMACS_gpu_cluster\", scale=6)\n",
    "    @mpi_task(cluster_id=\"GROMACS_gpu_cluster\")\n",
    "    def run_mpi_gpu(**kwargs):\n",
    "        print(which(\"gmx\"))\n",
    "        script_path = os.path.join(\n",
    "            os.getenv(\"JOBQUEUE_FEATURES_EXAMPLES\"), \"resources\", \"helloworld2.py\"\n",
    "        )\n",
    "        t = mpi_wrap(\n",
    "            pre_launcher_opts='time -f \"%e\"',\n",
    "            executable=\"python\",\n",
    "            exec_args=script_path,\n",
    "            **kwargs\n",
    "        )\n",
    "        return t\n",
    "\n",
    "\n",
    "if HSW:\n",
    "\n",
    "    @on_cluster(cluster=GROMACS_cluster, cluster_id=\"GROMACS_cluster\")\n",
    "    @mpi_task(cluster_id=\"GROMACS_cluster\")\n",
    "    def run_mpi(**kwargs):\n",
    "        print(which(\"gmx\"))\n",
    "        script_path = os.path.join(\n",
    "            os.getenv(\"JOBQUEUE_FEATURES_EXAMPLES\"), \"resources\", \"helloworld2.py\"\n",
    "        )\n",
    "        t = mpi_wrap(\n",
    "            pre_launcher_opts='time -f \"%e\"',\n",
    "            executable=\"python\",\n",
    "            exec_args=script_path,\n",
    "            **kwargs\n",
    "        )\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_example():\n",
    "    t_gpu = []\n",
    "    t = []\n",
    "\n",
    "    n_samples = 10\n",
    "    for x in range(n_samples):\n",
    "        if GPU:\n",
    "            t_gpu.append(run_mpi_gpu())\n",
    "        if HSW:\n",
    "            t.append(run_mpi())\n",
    "\n",
    "    if GPU:\n",
    "        runtimes_gpu = [float((i.result()[\"err\"]).split(b\"\\n\")[-2]) for i in t_gpu]\n",
    "        print(\"Example command:\\n{}\".format(t_gpu[0].result()[\"cmd\"]))\n",
    "        print(\"Example output:\\n{}\".format(t_gpu[0].result()[\"out\"]))\n",
    "        print(\n",
    "            \"GPU Compute Total (\",\n",
    "            len(runtimes_gpu),\n",
    "            \" samples) \",\n",
    "            sum(runtimes_gpu),\n",
    "            \" : Average \",\n",
    "            np.mean(runtimes_gpu),\n",
    "            \" +/- \",\n",
    "            np.var(runtimes_gpu),\n",
    "        )\n",
    "    if HSW:\n",
    "        runtimes = [float((i.result()[\"err\"]).split(b\"\\n\")[-2]) for i in t]\n",
    "        print(\"Example command:\\n{}\".format(t[0].result()[\"cmd\"]))\n",
    "        print(\"Example output:\\n{}\".format(t[0].result()[\"out\"]))\n",
    "        print(\n",
    "            \"Cluster Compute Total (\",\n",
    "            len(runtimes),\n",
    "            \" samples)\",\n",
    "            sum(runtimes),\n",
    "            \" : Average \",\n",
    "            np.mean(runtimes),\n",
    "            \" +/- \",\n",
    "            np.var(runtimes),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "complex_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But where is the output of\n",
    "```python\n",
    "print(which(\"gmx\"))\n",
    "```\n",
    "in `run_mpi`/`run_mpi_gpu`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jobqueue",
   "language": "python",
   "name": "jobqueue"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
